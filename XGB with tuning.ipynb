{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22290b80",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11360/2618282226.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \"\"\"\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_spectral\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mspectral_clustering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSpectralClustering\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m from ._mean_shift import (mean_shift, MeanShift,\n\u001b[0;32m      8\u001b[0m                           estimate_bandwidth, get_bin_seeds)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_spectral.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_deprecate_positional_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpairwise_kernels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkneighbors_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNearestNeighbors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanifold\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mspectral_embedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_classification\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmultilabel_confusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcluster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0madjusted_mutual_info_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0madjusted_rand_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "train = pd.read_csv(\"CSV_train.csv\",low_memory=False,delimiter=';')\n",
    "test=pd.read_csv(\"CSV_test.csv\",low_memory=False,delimiter=',')\n",
    "hidden=pd.read_csv(\"CSV_hidden_test.csv\",low_memory=False,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccf6fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346cf516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing length of datasets \n",
    "train_len = train.shape[0] \n",
    "test_len = test.shape[0]\n",
    "All_data = pd.concat((train,test,hidden)).reset_index(drop=True) \n",
    "\n",
    "lithology_keys = {30000: 'Sandstone',\n",
    "                 65030: 'Sandstone/Shale',\n",
    "                 65000: 'Shale',\n",
    "                 80000: 'Marl',\n",
    "                 74000: 'Dolomite',\n",
    "                 70000: 'Limestone',\n",
    "                 70032: 'Chalk',\n",
    "                 88000: 'Halite',\n",
    "                 86000: 'Anhydrite',\n",
    "                 99000: 'Tuff',\n",
    "                 90000: 'Coal',\n",
    "                 93000: 'Basement'}\n",
    "All_data['Lithology'] = All_data['FORCE_2020_LITHOFACIES_LITHOLOGY'].map(lithology_keys)\n",
    "All_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7268debf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping columns with high missing values\n",
    "drop_cols = ['SGR', 'ROPA', 'RXO', 'MUDWEIGHT','DCAL','RMIC','FORCE_2020_LITHOFACIES_CONFIDENCE']\n",
    "All_data_drop = All_data.drop(drop_cols, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4f9b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "All_data_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0a8ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b595514",
   "metadata": {},
   "outputs": [],
   "source": [
    "All_data_drop.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c4d861",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputing missing values by introducing median \n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "numeric_header=['DEPTH_MD', 'X_LOC', 'Y_LOC', 'Z_LOC',\n",
    "       'CALI', 'RSHA', 'RMED', 'RDEP', 'RHOB', 'GR', 'NPHI', 'PEF', 'DTC',\n",
    "       'SP', 'BS', 'ROP', 'DTS', 'DRHO', 'FORCE_2020_LITHOFACIES_LITHOLOGY'\n",
    "       ]\n",
    "categorical_header=['WELL','GROUP', 'FORMATION','Lithology']\n",
    "numeric=All_data_drop.select_dtypes(include=[np.number])\n",
    "categorical= All_data_drop.select_dtypes(exclude=[np.number])\n",
    "miss = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "miss.fit(numeric)\n",
    "numeric_imp = miss.fit_transform(numeric)\n",
    "numeric_imp=pd.DataFrame(numeric_imp, columns=numeric_header)\n",
    "miss2 = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "miss2.fit(categorical)\n",
    "categorical_imp = miss2.fit_transform(categorical)\n",
    "categorical_imp=pd.DataFrame(categorical_imp, columns=categorical_header)\n",
    "frames = [numeric_imp,categorical_imp]\n",
    "  \n",
    "result = pd.concat(frames,axis=1, join='inner')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2061b53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding categorical variables\n",
    "result['GROUP_encoded'] = result['GROUP'].astype('category')\n",
    "result['GROUP_encoded'] = result['GROUP_encoded'].cat.codes\n",
    "\n",
    "result['FORMATION_encoded'] = result['FORMATION'].astype('category')\n",
    "result['FORMATION_encoded'] = result['FORMATION_encoded'].cat.codes\n",
    "\n",
    "result['WELL_encoded'] = result['WELL'].astype('category')\n",
    "result['WELL_encoded'] = result['WELL_encoded'].cat.codes\n",
    "\n",
    "result['Lithology_encoded'] = result['FORCE_2020_LITHOFACIES_LITHOLOGY'].astype('category')\n",
    "result['Lithology_encoded'] = result['Lithology_encoded'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c3ec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping categorial features replaces beforehan by encoded features\n",
    "# drop2 = All_data_drop.drop(['GROUP', 'FORMATION','WELL','FORCE_2020_LITHOFACIES_LITHOLOGY','Lithology'], axis=1)\n",
    "\n",
    "# # splitting dataset into training, test, and hidden sets\n",
    "# train_prep = drop2[:train_len].copy()\n",
    "# test_prep = drop2[train_len:(train_len+test_len)].copy()\n",
    "# hidden_prep = drop2[(train_len+test_len):].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075959da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_prep1= train_prep.copy()\n",
    "# test_prep1= test_prep.copy()\n",
    "# hidden_prep1= hidden_prep.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426f0612",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imp = result[:train_len].copy()\n",
    "test_imp = result[train_len:(train_len+test_len)].copy()\n",
    "hidden_imp = result[(train_len+test_len):].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb06db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_imp.shape)\n",
    "print(test_imp.shape)\n",
    "print(hidden_imp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81f8662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler\n",
    "x_header=['DEPTH_MD', 'X_LOC', 'Y_LOC', 'Z_LOC', 'CALI', 'RSHA', 'RMED', 'RDEP',\n",
    "       'RHOB', 'GR', 'NPHI', 'PEF', 'DTC', 'SP', 'BS', 'ROP', 'DTS', 'DRHO',\n",
    "       'GROUP_encoded', 'FORMATION_encoded', 'WELL_encoded']\n",
    "y_header=['Lithology_encoded']\n",
    "x_train = train_imp[x_header]\n",
    "y_train = train_imp[y_header]\n",
    "x_test = test_imp[x_header]\n",
    "y_test = test_imp[y_header]\n",
    "x_hidden = hidden_imp[x_header]\n",
    "y_hidden = hidden_imp[y_header]\n",
    "\n",
    "##Min-Max scaler \n",
    "scaler = MinMaxScaler()\n",
    "x_train_scaled = x_train.copy()\n",
    "x_test_scaled = x_test.copy()\n",
    "x_hidden_scaled = x_hidden.copy()\n",
    "\n",
    "x_train_scaled.iloc[:,:18] = scaler.fit_transform(x_train_scaled.iloc[:,:18])\n",
    "x_test_scaled.iloc[:,:18] = scaler.transform(x_test_scaled.iloc[:,:18])\n",
    "x_hidden_scaled.iloc[:,:18] = scaler.transform(x_hidden_scaled.iloc[:,:18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c32cde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e419d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04af7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  import numpy as np\n",
    "#     matrix_path = '/content/drive/MyDrive/Thesis_data/penalty_matrix.npy'\n",
    "#     A = np.load(matrix_path)\n",
    "#     S = 0.0\n",
    "#     y_true = y_true.astype(int)\n",
    "#     y_pred = y_pred.astype(int)\n",
    "#     for i in range(0, y_true.shape[0]):\n",
    "#         S -= A[y_true[i], y_pred[i]]\n",
    "#     return S/y_true.shape[0]\n",
    "    \n",
    "# # Confusion Matrix Function\n",
    "\n",
    "# def confusion_matrix(y_true, y_pred):\n",
    "      \n",
    "#     \"\"\"Plots a confusion matrix normalized by the number of predictions a particular\n",
    "#     machine learning algorithm has. By ormalize we look at the number of predictions\n",
    "#     the model gets right.\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     y_true: list\n",
    "#       The actual lithologies given by the datasets provider.\n",
    "#     y_pred: list\n",
    "#       The predicted lithofacies obtained by a particular machine learning model.\n",
    "#     Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb35ab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.load('penalty_matrix.npy')\n",
    "def score(y_true, y_pred):\n",
    "    S = 0.0\n",
    "    y_true = y_true.astype(int)\n",
    "    y_pred = y_pred.astype(int)\n",
    "    for i in range(0, y_true.shape[0]):\n",
    "        S -= A[y_true[i], y_pred[i]]\n",
    "    return S/y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49e9557",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Supervised Algorithms\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#Comparing base models accuracies by using k-fold cross validation - 10 folds\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "new_train = pd.concat((x_train_scaled, pd.DataFrame(y_train, columns=[\"Lithology_encoded\"])), axis=1)\n",
    "\n",
    "#Randomly sampling data\n",
    "sampled_train = new_train.sample(n=50000, random_state=0)\n",
    "\n",
    "\n",
    "#Spliting training data\n",
    "x_train_sam = sampled_train.drop([\"Lithology_encoded\"], axis=1)\n",
    "y_train_sam = sampled_train[\"Lithology_encoded\"]\n",
    "\n",
    "model_xgb = XGBClassifier(n_estimators=1000, max_depth=4,\n",
    "                                 booster='gbtree', objective='multi:softprob',\n",
    "                                 learning_rate=0.075, random_state=42,\n",
    "                                 subsample=1, colsample_bytree=1,\n",
    "                                 tree_method='gpu_hist', predictor='gpu_predictor',\n",
    "                                 verbose=2020, reg_lambda=1500)\n",
    "\n",
    "model_xgb.fit(x_train_sam, y_train_sam.values.ravel(), early_stopping_rounds=100, eval_set=[(x_test, y_test)], verbose=100)\n",
    "\n",
    "train_pred_xgb = model_xgb.predict(x_train_scaled)\n",
    "open_pred_xgb = model_xgb.predict(x_test_scaled)\n",
    "hidden_pred_xgb = model_xgb.predict(x_hidden_scaled)\n",
    "#Printing Reports \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed47b302",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('-----------------------TRAIN SET REPORT---------------------')\n",
    "print(\"Open set RMSE:\", np.sqrt(mean_squared_error(y_train, train_pred_xgb)))\n",
    "print('Open set penalty matrix score:', score(y_train.values, train_pred_xgb))\n",
    "print('Open set report:', classification_report(y_train, train_pred_xgb))\n",
    "print('-----------------------OPEN SET REPORT---------------------')\n",
    "print(\"Open set RMSE:\", np.sqrt(mean_squared_error(y_test, open_pred_xgb)))\n",
    "print('Open set penalty matrix score:', score(y_test.values, open_pred_xgb))\n",
    "print('Open set report:', classification_report(y_test, open_pred_xgb))\n",
    "print('-----------------------HIDDEN SET REPORT---------------------')\n",
    "print(\"Hidden set RMSE:\", np.sqrt(mean_squared_error(y_hidden, hidden_pred_xgb)))\n",
    "print('Hidden set penalty matrix score:', score(y_hidden.values, hidden_pred_xgb))\n",
    "print('Hidden set report:', classification_report(y_hidden, hidden_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749f6203",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def grid_search(model):\n",
    "#     params = {'max_depth': [3, 6, 10, 15],\n",
    "#               'learning_rate': [0.01, 0.1, 0.2],\n",
    "#               'subsample': np.arange(0.5, 1.0, 0.1),\n",
    "#               'colsample_bytree': np.arange(0.5, 1.0, 0.1),\n",
    "#               'colsample_bylevel': np.arange(0.5, 1.0, 0.1),\n",
    "#               'n_estimators': [250,500,750],\n",
    "#               'num_class': [10]\n",
    "#               }\n",
    "#     model_cv = model_selection.GridSearchCV(estimator=model, param_grid=params,\n",
    "#                                           scoring='f1_weighted', verbose=10, n_jobs=1, cv=10)\n",
    "#     model_cv.fit(x_train_sam, y_train_sam)\n",
    "\n",
    "#     print(\"Best score is: {}\".format(model_cv.best_score_))\n",
    "#     print(\"Tuned Model Parameter: {}\".format(model_cv.best_params_))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1cd6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search(model_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed93ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Supervised Algorithms\n",
    "# from sklearn import model_selection\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "# from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.metrics import mean_squared_error, accuracy_score, recall_score, precision_score, f1_score\n",
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "# from pprint import pprint\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# import xgboost\n",
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# #Comparing base models accuracies by using k-fold cross validation - 10 folds\n",
    "\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# #Sampling Standarized Tarining Data to Optimize Time - DEPLOYING BASE MODEL\n",
    "# #Merging train data\n",
    "# new_train = pd.concat((x_train_scaled, pd.DataFrame(y_train, columns=[\"Lithology_encoded\"])), axis=1)\n",
    "\n",
    "# #Randomly sampling data\n",
    "# sampled_train = new_train.sample(n=819358, random_state=0)\n",
    "\n",
    "\n",
    "# #Spliting training data\n",
    "# x_train_sam = sampled_train.drop([\"Lithology_encoded\"], axis=1)\n",
    "# y_train_sam = sampled_train[\"Lithology_encoded\"]\n",
    "\n",
    "# new_test = pd.concat((x_test_scaled, pd.DataFrame(y_test, columns=[\"Lithology_encoded\"])), axis=1)\n",
    "\n",
    "# #Randomly sampling data\n",
    "# sampled_test = new_test.sample(n=120000, random_state=None)\n",
    "\n",
    "\n",
    "# #Spliting test data\n",
    "# x_test_sam = sampled_test.drop([\"Lithology_encoded\"], axis=1)\n",
    "# y_test_sam = sampled_test[\"Lithology_encoded\"]\n",
    "# model_xgb = XGBClassifier()\n",
    "\n",
    "# model_xgb.fit(x_train_sam, y_train_sam.values.ravel(), early_stopping_rounds=100, eval_set=[(x_test_sam, y_test_sam)], verbose=100)\n",
    "\n",
    "# train_pred_xgb = model_xgb.predict(x_train_sam)\n",
    "# open_pred_xgb = model_xgb.predict(x_test_sam)\n",
    "# hidden_pred_xgb = model_xgb.predict(x_hidden)\n",
    "# #Printing Reports \n",
    "\n",
    "# print('-----------------------TRAIN SET REPORT---------------------')\n",
    "# print(\"Open set RMSE:\", np.sqrt(mean_squared_error(y_train, train_pred_xgb)))\n",
    "# print('Open set penalty matrix score:', score(y_train.values, train_pred_xgb))\n",
    "# print('Open set report:', metrics.classification_report(y_train, train_pred_xgb))\n",
    "# print('-----------------------OPEN SET REPORT---------------------')\n",
    "# print(\"Open set RMSE:\", np.sqrt(mean_squared_error(y_test, open_pred_xgb)))\n",
    "# print('Open set penalty matrix score:', score(y_test.values, open_pred_xgb))\n",
    "# print('Open set report:', metrics.classification_report(y_test, open_pred_xgb))\n",
    "# print('-----------------------HIDDEN SET REPORT---------------------')\n",
    "# print(\"Hidden set RMSE:\", np.sqrt(mean_squared_error(y_hidden, hidden_pred_xgb)))\n",
    "# print('Hidden set penalty matrix score:', score(y_hidden.values, hidden_pred_xgb))\n",
    "# print('Hidden set report:', metrics.classification_report(y_hidden, hidden_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc29645",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
